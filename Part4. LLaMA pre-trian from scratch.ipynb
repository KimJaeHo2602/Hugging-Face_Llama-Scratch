{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55489e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82103\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1486: FutureWarning: The repository for ccdv/cnn_dailymail contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ccdv/cnn_dailymail\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "raw_dataset = load_dataset('ccdv/cnn_dailymail', '3.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f65368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 287113\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 13368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'highlights', 'id'],\n",
       "        num_rows: 11490\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97594d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours afte\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'][0]['article'][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e4ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wan...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of t...</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world cham...</td>\n",
       "      <td>Usain Bolt wins third gold of world championsh...</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kansas City, Missouri (CNN) -- The General Ser...</td>\n",
       "      <td>The employee in agency's Kansas City office is...</td>\n",
       "      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Los Angeles (CNN) -- A medical doctor in Vanco...</td>\n",
       "      <td>NEW: A Canadian doctor says she was part of a ...</td>\n",
       "      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(CNN) -- Police arrested another teen Thursday...</td>\n",
       "      <td>Another arrest made in gang rape outside Calif...</td>\n",
       "      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287108</th>\n",
       "      <td>Tiger Woods’s frustration at the lamentable st...</td>\n",
       "      <td>Woods said: ’Guys, give me a little f***ing sp...</td>\n",
       "      <td>fffdfb56fdf1a12d364562cc2b9b1d4de7481dee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287109</th>\n",
       "      <td>By . Mark Duell . Last updated at 4:07 PM on 2...</td>\n",
       "      <td>13 sailors died in 1804 after explosives ship ...</td>\n",
       "      <td>fffeecb8690b85de8c3faed80adbc7a978f9ae2a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287110</th>\n",
       "      <td>Suicide: Troll victim Hannah Smith, 14, killed...</td>\n",
       "      <td>Hannah Smith's father says Ask.fm's safety cha...</td>\n",
       "      <td>ffff5231e4c71544bc6c97015cdb16c60e42b3f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287111</th>\n",
       "      <td>By . Victoria Woollaston and Mark Prigg . PUBL...</td>\n",
       "      <td>A test version of Windows 8.1 is available to ...</td>\n",
       "      <td>ffff924b14a8d82058b6c1c5368ff1113c1632af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287112</th>\n",
       "      <td>Under fire Australian Defence Minister David J...</td>\n",
       "      <td>Defence Minister David Johnston said his 'I wo...</td>\n",
       "      <td>ffffd563a96104f5cf4493cfa701a65f31b06abf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287113 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  article  \\\n",
       "0       It's official: U.S. President Barack Obama wan...   \n",
       "1       (CNN) -- Usain Bolt rounded off the world cham...   \n",
       "2       Kansas City, Missouri (CNN) -- The General Ser...   \n",
       "3       Los Angeles (CNN) -- A medical doctor in Vanco...   \n",
       "4       (CNN) -- Police arrested another teen Thursday...   \n",
       "...                                                   ...   \n",
       "287108  Tiger Woods’s frustration at the lamentable st...   \n",
       "287109  By . Mark Duell . Last updated at 4:07 PM on 2...   \n",
       "287110  Suicide: Troll victim Hannah Smith, 14, killed...   \n",
       "287111  By . Victoria Woollaston and Mark Prigg . PUBL...   \n",
       "287112  Under fire Australian Defence Minister David J...   \n",
       "\n",
       "                                               highlights  \\\n",
       "0       Syrian official: Obama climbed to the top of t...   \n",
       "1       Usain Bolt wins third gold of world championsh...   \n",
       "2       The employee in agency's Kansas City office is...   \n",
       "3       NEW: A Canadian doctor says she was part of a ...   \n",
       "4       Another arrest made in gang rape outside Calif...   \n",
       "...                                                   ...   \n",
       "287108  Woods said: ’Guys, give me a little f***ing sp...   \n",
       "287109  13 sailors died in 1804 after explosives ship ...   \n",
       "287110  Hannah Smith's father says Ask.fm's safety cha...   \n",
       "287111  A test version of Windows 8.1 is available to ...   \n",
       "287112  Defence Minister David Johnston said his 'I wo...   \n",
       "\n",
       "                                              id  \n",
       "0       0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1       0002095e55fcbd3a2f366d9bf92a95433dc305ef  \n",
       "2       00027e965c8264c35cc1bc55556db388da82b07f  \n",
       "3       0002c17436637c4fe1837c935c04de47adb18e9a  \n",
       "4       0003ad6ef0c37534f80b55b4235108024b407f0b  \n",
       "...                                          ...  \n",
       "287108  fffdfb56fdf1a12d364562cc2b9b1d4de7481dee  \n",
       "287109  fffeecb8690b85de8c3faed80adbc7a978f9ae2a  \n",
       "287110  ffff5231e4c71544bc6c97015cdb16c60e42b3f4  \n",
       "287111  ffff924b14a8d82058b6c1c5368ff1113c1632af  \n",
       "287112  ffffd563a96104f5cf4493cfa701a65f31b06abf  \n",
       "\n",
       "[287113 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdec78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": raw_dataset['train'].select(range(50000)).shuffle(),\n",
    "        \"valid\": raw_dataset['test'].select(range(5000)).shuffle()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0bc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36c40ebb",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d9e725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b378eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus(ds):\n",
    "    return(\n",
    "        ds[i:i+1000]['article'] for i in range(0, len(ds), 1000)\n",
    "    )\n",
    "\n",
    "\n",
    "training_corpus = get_training_corpus(raw_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc3fd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16min 40s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = tokenizer.train_new_from_iterator(training_corpus, vocab_size=50257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013ec5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'Ġofficial',\n",
       " ':',\n",
       " 'ĠU',\n",
       " '.',\n",
       " 'S',\n",
       " '.',\n",
       " 'ĠPresident',\n",
       " 'ĠBarack',\n",
       " 'ĠObama',\n",
       " 'Ġwants',\n",
       " 'Ġlawmakers',\n",
       " 'Ġto',\n",
       " 'Ġweigh',\n",
       " 'Ġin',\n",
       " 'Ġon',\n",
       " 'Ġwhether',\n",
       " 'Ġto',\n",
       " 'Ġuse',\n",
       " 'Ġmilitary',\n",
       " 'Ġforce',\n",
       " 'Ġin',\n",
       " 'ĠSyria']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria\"\n",
    "\n",
    "tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c57835d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [868, 345, 1061, 26, 458, 14, 51, 14, 1497, 4149, 1288, 2880, 8505, 280, 6284, 285, 316, 1714, 280, 1321, 1681, 2692, 285, 2730], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'length': [24]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(sample_text, return_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b9e8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 128\n",
    "\n",
    "def tokenize(batch):\n",
    "    outputs = tokenizer(\n",
    "        batch['article'],\n",
    "        max_length=context_length,\n",
    "        truncation=True,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True\n",
    "    )\n",
    "    \n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs['length'], outputs['input_ids']):\n",
    "        if length==context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9864fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cf08a1f09c40d4817a69400cf65e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cab62f8ec94af2b870e4be65009fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = sampled_dataset.map(tokenize, batched=True, remove_columns=raw_dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596122d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdd38c8f",
   "metadata": {},
   "source": [
    "## load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc2b5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.39.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaConfig\n",
    "\n",
    "configuration = LlamaConfig()\n",
    "\n",
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b388dce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 50257)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.bos_token_id, tokenizer.eos_token_id, tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9648d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = LlamaConfig(**{\n",
    "  \"bos_token_id\": 50256,\n",
    "  \"eos_token_id\": 50256,\n",
    "  \"hidden_act\": \"silu\",\n",
    "  \"hidden_size\": 512,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"intermediate_size\": 1376,\n",
    "  \"max_position_embeddings\": 128,\n",
    "  \"model_type\": \"llama\",\n",
    "  \"num_attention_heads\": 4,\n",
    "  \"num_hidden_layers\": 4,\n",
    "  \"pad_token_id\": 0,\n",
    "  \"rms_norm_eps\": 1e-06,\n",
    "  \"tie_word_embeddings\": False,\n",
    "  \"transformers_version\": \"4.28.0\",\n",
    "  \"use_cache\": True,\n",
    "  \"vocab_size\": 50257\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8680f44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "model = LlamaForCausalLM(configuration)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "418242ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb62f7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e0a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82103\\anaconda3\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:670: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  868,   345,  1061,    26,   458,    14,    51,    14,  1497,  4149,\n",
       "          1288,  2880,  8505,   280,  6284,   285,   316,  1714,   280,  1321,\n",
       "          1681,  2692,   285,   221,  5429, 23773, 42462,  5429, 23773,  3683,\n",
       "         23773,  3683, 23773,  3683, 45643,  9751, 24287, 45643,  5839, 45643,\n",
       "          5839,  5839,  5839,  5839,  5839, 45643,  5839,  5839,  5839, 45643]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "generate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77d55bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in  militants Kra Soubry militants Kra Sand Kra Sand Kra Sand Mathe profit Malm Mathe potentially Mathe potentially potentially potentially potentially potentially Mathe potentially potentially potentially Mathe\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ee05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924b02b2",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fed72a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05695613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([3, 128])\n",
      "attention_mask: torch.Size([3, 128])\n",
      "labels: torch.Size([3, 128])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "\n",
    "for key in out:\n",
    "    print(f\"{key}: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f272d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    8,  1356,     9,   630,  3006,  1751, 17413,  4350,  5697,   259,\n",
       "         12520,   285,  3213,   316,  1555,  3596,   359, 24214, 17486,   345]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([    8,  1356,     9,   630,  3006,  1751, 17413,  4350,  5697,   259,\n",
       "         12520,   285,  3213,   316,  1555,  3596,   359, 24214, 17486,   345]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['input_ids'][0][:20], out['attention_mask'][0][:20], out['labels'][0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063853d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92c33124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 32\n",
    "logging_steps = 1000\n",
    "learning_rate=5e-4\n",
    "num_epochs=1\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='newsllama',\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=logging_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    save_steps=logging_steps,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=logging_steps,\n",
    "    lr_scheduler_type='cosine',\n",
    "    learning_rate=5e-4,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "397824ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82103\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcf2e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24844402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4614426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe4b4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7ee4d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  868,   345,  1061,    26,   458,    14,    51,    14,  1497,  4149,\n",
       "          1288,  2880,  8505,   280,  6284,   285,   316,  1714,   280,  1321,\n",
       "          1681,  2692,   285,   221,  5429, 23773, 42462,  5429, 23773,  3683,\n",
       "         23773,  3683, 23773,  3683, 45643,  9751, 24287, 45643,  5839, 45643,\n",
       "          5839,  5839,  5839,  5839,  5839, 45643,  5839,  5839,  5839, 45643]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "generate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad640098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in  militants Kra Soubry militants Kra Sand Kra Sand Kra Sand Mathe profit Malm Mathe potentially Mathe potentially potentially potentially potentially potentially Mathe potentially potentially potentially Mathe\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0e1273e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in tem sentenced militants militants militants militants militants militants palsy Ribery Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm Malm\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de7889d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shall I compare thee to a summer’s day?\\nThou art more lovely and more temperate:\\nRough winds do shake the recruenza Soul cheerful McNamara McNamara McNamara McNamara Industry Kathy Soul Industry Soul Industry Soul Industry Soul Soul.''\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Shall I compare thee to a summer’s day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "523c2855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in Mam gobsmacked gobsmacked gobsmacked gobsmacked gobsmacked allowanceschainedstudded Swanson Suz multimletplane Braz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973f430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989504b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94814a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7cdb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c2e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be4a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5145ce53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a5dc929",
   "metadata": {},
   "source": [
    "## train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f116be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcf1758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([3, 128])\n",
      "attention_mask: torch.Size([3, 128])\n",
      "labels: torch.Size([3, 128])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets['train'][i] for i in range(3)])\n",
    "\n",
    "for key in out:\n",
    "    print(f\"{key}: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2feb25df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    8,  1356,     9,   630,  3006,  1751, 17413,  4350,  5697,   259,\n",
       "         12520,   285,  3213,   316,  1555,  3596,   359, 24214, 17486,   345]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([    8,  1356,     9,   630,  3006,  1751, 17413,  4350,  5697,   259,\n",
       "         12520,   285,  3213,   316,  1555,  3596,   359, 24214, 17486,   345]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['input_ids'][0][:20], out['attention_mask'][0][:20], out['labels'][0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e91aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850e458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4146cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size=32\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"newsllama\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=5_00,\n",
    "    logging_steps=5_00,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type='cosine',\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d710b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a803ae50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1139' max='1139' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1139/1139 22:32, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.160400</td>\n",
       "      <td>6.069175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.075200</td>\n",
       "      <td>5.395545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1139, training_loss=5.938820534991632, metrics={'train_runtime': 1353.9875, 'train_samples_per_second': 215.516, 'train_steps_per_second': 0.841, 'total_flos': 8595722395975680.0, 'train_loss': 5.938820534991632, 'epoch': 1.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6776dc3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in the country. \"I think it\\'s a very important thing to do,\" Obama said. \"I think it\\'s a very important thing'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b4ae0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shall I compare thee to a summer’s day?\\nThou art more lovely and more temperate:\\nRough winds do shake the way to the sun. The most important thing is that the sun is to be the most important'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Shall I compare thee to a summer’s day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8fa7d6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in the study of the study, which was published in the journal Science and Research'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in\"\"\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "# Generate\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea48640e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24336f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205ad40b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81907c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ee5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2908ca19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Some implementations of machine learning use data and neural networks. The company's website says it has been working with the company for more than a decade. The company has been working on a new Web site, and the company has been working on a new\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Some implementations of machine learning use data and neural networks\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9918c7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Shall I compare thee to a summer’s day?\\nThou art more lovely and more temperate:\\nRough winds do shake the darling buds of May, and the sun's most famous, the most popular, the most popular\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Shall I compare thee to a summer’s day?\n",
    "Thou art more lovely and more temperate:\n",
    "Rough winds do shake the darling buds of May,\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e56021bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It\\'s official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in  the United States. \"I think it\\'s a very important thing to do,\" Obama said. \"I think it\\'s a very'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in \"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "inputs.to(device)\n",
    "\n",
    "generate_ids = model.generate(inputs.input_ids, max_length=50)\n",
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7d33fb7-5d01-4708-b09a-69ba49e3d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"daily_tokenizer_0612\")\n",
    "model.save_pretrained('daily_llama_0612')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72357df7-1116-41bf-9559-39775042b3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aebc53d-106f-4579-aacc-239e3458178b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
