{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2388ea-8e4a-4bd9-a7bf-dc0507a9bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d70dfd4-885a-4492-955b-48dbf857d304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(50257, 512, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1376, bias=False)\n",
       "          (down_proj): Linear(in_features=1376, out_features=512, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import LlamaForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('daily_tokenizer_0612')\n",
    "model = LlamaForCausalLM.from_pretrained('daily_llama_0612')\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb97e6-8a5b-45c7-a29a-21a2374f5db7",
   "metadata": {},
   "source": [
    "# dataset불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54032190-bf3e-45c6-8865-746133a38544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 24353\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'title', 'text', 'label'],\n",
       "        num_rows: 8117\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import DatasetDict\n",
    "\n",
    "data = 'GonzaloA/Fake_news'\n",
    "dataset_fake = load_dataset(data)\n",
    "dataset_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca19eee-7dee-4b73-b47b-04038e5dafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset은 train, test를 split하면서 생상헐꺼니 냅두고, validation set을 없애준다.\n",
    "dataset_fake = DatasetDict({'train': dataset_fake['train'], 'test':dataset_fake['test']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3b95015-54a4-4547-ab22-103c7572b258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['Unnamed: 0', 'title', 'text', 'label'],\n",
       " 'test': ['Unnamed: 0', 'title', 'text', 'label']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fake.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ddd05a-158f-4040-8f0a-5f9c68118775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category 데이터셋을 불러오고, 전처리가 필요하다.\n",
    "data = 'heegyu/news-category-balanced-top10'\n",
    "\n",
    "dataset_cate = load_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4d4a65e-6193-4bc2-b9e4-7a3181496872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['link', 'headline', 'category', 'short_description', 'authors', 'date', 'label'],\n",
       "        num_rows: 29026\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cate # train datset밖에 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b6a8882-164d-40e6-918d-54ede77cedf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BUSINESS', 'ENTERTAINMENT', 'FOOD & DRINK', 'HEALTHY LIVING']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = dataset_cate['train'].to_pandas().category.unique().tolist()\n",
    "categories.sort()\n",
    "categories = categories[:4]\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d257da62-9396-444f-8fb5-5501be2460d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e60a6753934657b5f1f13a7fa6d1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/29026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['link', 'headline', 'category', 'short_description', 'authors', 'date'],\n",
       "        num_rows: 29026\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위 4개의 카테고리에 속해있는 데이터만 걸러준다.\n",
    "dataset_cate = dataset_cate.filter(lambda element: element['category'] in categories)\n",
    "dataset_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e63754b-0ccc-4a2e-94c6-c111f3d8f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake news mapping\n",
    "int2label_fake = {0: 'False', 1: 'True'}\n",
    "label2int_fake = {'False': 0, 'True':1}\n",
    "\n",
    "# categories news mapping\n",
    "\n",
    "categories = [x.split(' ')[0].lower() for x in categories] # 첫번째 단어만 취해서 소문자만 사용\n",
    "int2label_cate = {i: categories[i] for i in range(len(categories))} # 정수 label이 없으므로 임의로 부여해서 dictonary를 만들어준다\n",
    "label2int_cate = {int2label_cate[key]: key for key in int2label_cate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b8d161a-93e3-4b8b-bdb1-bc7d6a7d86f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9002d839122943cfb68cc7055f5070f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29026 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# category label 정제\n",
    "def gen_label(element):\n",
    "    category = element['category'].split(' ')[0].lower() # 첫번쨰 단어만 취해서 소문자로 바꿔준다\n",
    "    return {'label': label2int_cate[category], 'category': category}\n",
    "\n",
    "dataset_cate = dataset_cate.map(gen_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f9cae6-3a42-4f79-8f59-ce9ea989f9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['link', 'headline', 'category', 'short_description', 'authors', 'date', 'label'],\n",
       "        num_rows: 26123\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['link', 'headline', 'category', 'short_description', 'authors', 'date', 'label'],\n",
       "        num_rows: 2903\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train dataset밖에 없으므로 쪼개준다.\n",
    "dataset_cate = dataset_cate['train'].train_test_split(test_size=0.1)\n",
    "dataset_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a06c3300-250e-41f0-b1cb-269c8793f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "from datasets import concatenate_datasets\n",
    "import random\n",
    "\n",
    "# prompt_fake\n",
    "prompt_format1_fake = \"\"\"Determine if the given article is fake. article: %s  answer: %s\"\"\"\n",
    "prompt_format2_fake = \"\"\"Is this article fake? article: %s answer: %s\"\"\"\n",
    "prompt_format3_fake = \"\"\"Return True if the given article is fake. article: %s answer: %s\"\"\"\n",
    "\n",
    "prompts_fake = [prompt_format1_fake, prompt_format2_fake, prompt_format3_fake]\n",
    "\n",
    "def gen_prompt_fake(element):\n",
    "    prompt_format = prompts_fake[random.randint(0, len(prompts_fake)-1)]\n",
    "    return DatasetDict({'input': prompt_format%(element['title'], int2label_fake[element['label']])}) #본분 역할이 title\n",
    "\n",
    "# prompt_cate\n",
    "prompt_format1_cate = \"\"\"Given the article, what is the topic of the article? article: %s  answer: %s\"\"\"\n",
    "prompt_format2_cate = \"\"\"Determine the topic of the news article. article: %s answer: %s\"\"\"\n",
    "prompt_format3_cate = \"\"\"What is this article about? business/entertainment/food/healthy/parenting article: %s answer: %s\"\"\"\n",
    "\n",
    "prompts_cate = [prompt_format1_cate, prompt_format2_cate, prompt_format3_cate]\n",
    "\n",
    "def gen_prompt_cate(element):\n",
    "    prompt_format = prompts_cate[random.randint(0, len(prompts_cate)-1)]\n",
    "    return DatasetDict({'input': prompt_format%(element['headline'], int2label_cate[element['label']])}) #본문 역할이 headline\n",
    "\n",
    "train_fake = dataset_fake['train'].map(gen_prompt_fake, remove_columns=dataset_fake['train'].column_names)\n",
    "train_cate = dataset_cate['train'].map(gen_prompt_cate, remove_columns=dataset_cate['train'].column_names)\n",
    "\n",
    "train_dataset = concatenate_datasets([train_fake, train_cate]).shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77a3e229-7249-46cb-b6df-b0adcba9342e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df554ee6d1bc4d38bc973b8c2ad94385",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids'],\n",
       "    num_rows: 50476\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize\n",
    "def tokenize(element):\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    outputs = tokenizer(\n",
    "        element['input'],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_length=True,\n",
    "        padding=True        \n",
    "    )\n",
    "    return {'input_ids': outputs['input_ids']}\n",
    "    \n",
    "context_length=128\n",
    "tokenized_datasets = train_dataset.map(\n",
    "    tokenize, batched=True, remove_columns = train_dataset.column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89d68465-71f6-4c5c-8865-5a620a407309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([3, 67])\n",
      "attention_mask shape: torch.Size([3, 67])\n",
      "labels shape: torch.Size([3, 67])\n"
     ]
    }
   ],
   "source": [
    "# Data Collator\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "out = data_collator([tokenized_datasets[i] for i in range(3)])\n",
    "\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77e5c675-818c-48fd-8d90-929dd1ee6d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82103\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# traing argument\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"combied_instruct_llama\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1000,\n",
    "    #wawarmup_ratio=0.2\n",
    "    lr_scheduler_type='cosine',\n",
    "    learning_rate=5e-4,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8b50727-52aa-4db1-93bd-081c653fb1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82103\\anaconda3\\Lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:670: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1577' max='1577' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1577/1577 29:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1577, training_loss=2.7097949776077996, metrics={'train_runtime': 1772.2022, 'train_samples_per_second': 28.482, 'train_steps_per_second': 0.89, 'total_flos': 1006764006850560.0, 'train_loss': 2.7097949776077996, 'epoch': 1.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b6b72-61cb-47b5-a149-ac1098a268a2",
   "metadata": {},
   "source": [
    "### Fake_news classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30e749ae-4999-4435-a3e4-f4a1ef318bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09911d54201548b1affdf04153886d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925c36fb5d07464eabfbe635d0369443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "# prompt_fake\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('daily_tokenizer_0612', padding_side='left')\n",
    "\n",
    "prompt_format1 = \"\"\"Determine if the given article is fake. article: %s  answer:\"\"\"\n",
    "prompt_format2 = \"\"\"Is this article fake? article: %s answer:\"\"\"\n",
    "prompt_format3 = \"\"\"Return True if the given article is fake. article: %s answer:\"\"\"\n",
    "\n",
    "prompts = [prompt_format1, prompt_format2, prompt_format3]\n",
    "\n",
    "def gen_valid_prompt_fake(element):\n",
    "    prompt_format = prompts[random.randint(0, len(prompts)-1)]\n",
    "    return DatasetDict({'input': prompt_format%(element['title'])}) #label을 없애준다.\n",
    "\n",
    "valid_dataset = dataset_fake['test'].select(range(100)).map(gen_valid_prompt_fake)\n",
    "\n",
    "context_length=128\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize, batched=True, remove_columns=['text', 'input', 'Unnamed: 0', 'title']\n",
    ")\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7794e7ce-3351-41e6-a172-cf63bd5f9192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['Unnamed: 0', 'title', 'text', 'label'],\n",
       " 'test': ['Unnamed: 0', 'title', 'text', 'label']}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fake.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3251f4e1-ecb1-4d76-8d06-778fc2fbe018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader정의\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 4\n",
    "val_ds = valid_dataset\n",
    "val_ds.set_format(type='torch')\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af9a9533-2886-4674-8055-b2053f3f0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy 함수 정의\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def acc(pred,lable):\n",
    "    return torch.sum(torch.tensor(pred) == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c1343552-72f1-4026-a95c-2878bc746759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:16<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc:  0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# fake news 성능 확인\n",
    "\n",
    "model.eval()\n",
    "val_losses = []\n",
    "val_acc = 0\n",
    "\n",
    "for step, batch in enumerate(tqdm(val_dl)): # batch에서 label과 input_ids를 가져온다\n",
    "    label = batch['label']\n",
    "    input_id = batch['input_ids'].to(device)\n",
    "\n",
    "    pred = model.generate(input_id, max_length=128)\n",
    "    decoded_pred = tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    decoded_pred = [re.findall(\"answer: (True|False)\", x)[0] if re.findall(\"answer: (True|False)\", x) else 'none' for x in decoded_pred]\n",
    "    decoded_pred = [label2int_fake[x] if x in label2int_fake else -1 for x in decoded_pred]\n",
    "\n",
    "    val_acc += acc(decoded_pred, label)\n",
    "\n",
    "\n",
    "print(\"val acc: \", val_acc/((step+1)*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6fd07ee-7396-4dfa-b430-28f8baafed53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is this article fake? article: WATCH DIRTY HARRY REID ON HIS LIE ABOUT ROMNEY’S TAXES: “HE DIDN’T WIN, DID HE?” answer: Falsely Tries To Be “Large” answer: Falsely Tries To Be A “HILLARY” answer: Falsely Tries To Be A “HUGE” answer: Falsely Tries To Be A “HUGE” answer:',\n",
       " \"Is this article fake? article: North Korea diplomat says take atmospheric nuclear test threat 'literally' answer: True if Trump is 'very concerned' answer: True if U.S. is 'very concerned' about North Korea nuclear deal answer: True if Trump is 'very concerned' about U.S. nuclear deal answer: True if Trump is 'very concerned' answer\",\n",
       " 'Is this article fake? article: VIRAL VIDEO: German Youth Deliver Powerful Anti-Refugee Message To Political Leaders: “We are ready for the Reconquista!” answer: Falsely Tries To Make America Great answer: Falsely answer: Falsely” answer: Falsely Tries To Be President” [VIDEO] answer: Falsely Tries To Be A “Gilmore” [VIDEO] answer: Falsely T',\n",
       " \"Return True if the given article is fake. article: Polish ruling party replaces PM ahead of elections answer: True if EU's Tusk answer: True if EU is 'very concerned' answer: True if EU is 'very concerned' about Trump's Jerusalem move answer: True if it is 'very concerned' answer: True if U.S. is 'very concerned' about\"]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527eb778-f5bb-4bba-b801-590ea0b6e12a",
   "metadata": {},
   "source": [
    "# Category Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e4395fc-f2f3-4e47-a0f1-31310b0afbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids'],\n",
       "    num_rows: 2903\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('daily_tokenizer_0612', padding_side='left')\n",
    "\n",
    "prompt_format1 = \"\"\"Given the article, what is the topic of the article? article: %s  answer:\"\"\"\n",
    "prompt_format2 = \"\"\"Determine the topic of the news article. article: %s answer:\"\"\"\n",
    "prompt_format3 = \"\"\"What is this article about? business/entertainment/food/healthy/parenting article: %s answer:\"\"\"\n",
    "\n",
    "prompts = [prompt_format1, prompt_format2, prompt_format3]\n",
    "\n",
    "def gen_valid_prompt_cate(element):\n",
    "    prompt_format = prompts[random.randint(0, len(prompts)-1)]\n",
    "    return DatasetDict({'input': prompt_format%(element['headline'])}) #본문 역할이 headline #, int2label_cate[element['label']], label을 때준다\n",
    "\n",
    "valid_dataset = dataset_cate['test'].map(gen_valid_prompt_cate)\n",
    "\n",
    "context_length=128\n",
    "valid_dataset = valid_dataset.map(\n",
    "    tokenize, batched=True, remove_columns=['link', 'headline', 'category', 'short_description', 'authors', 'date', 'input']\n",
    ")\n",
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2f24e7c-4df6-41df-83bb-57667a05a9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['link',\n",
       "  'headline',\n",
       "  'category',\n",
       "  'short_description',\n",
       "  'authors',\n",
       "  'date',\n",
       "  'label'],\n",
       " 'test': ['link',\n",
       "  'headline',\n",
       "  'category',\n",
       "  'short_description',\n",
       "  'authors',\n",
       "  'date',\n",
       "  'label']}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_cate.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f0d4ba1-19f2-40a1-a764-2f7280729cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader 정의\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size=4\n",
    "val_ds = valid_dataset.select(range(100))\n",
    "val_ds.set_format(type='torch')\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9eb6d4f7-02c6-42ef-8d6e-164ee421a60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:26<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val acc:  0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_losses = []\n",
    "val_acc = 0\n",
    "\n",
    "for step, batch in enumerate(tqdm(val_dl)):\n",
    "    label = batch['label']\n",
    "    input_id = batch['input_ids'].to(device)\n",
    "\n",
    "    pred = model.generate(input_id, max_length=150)\n",
    "    decoded_pred = tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    decoded_pred = [re.findall(\"answer: ([a-z]+)\", x)[0] if re.findall(\"answer: ([a-z]+)\", x) else 'none' for x in decoded_pred]\n",
    "    decoded_pred = [label2int_cate[x] if x in label2int_cate else -1 for x in decoded_pred]\n",
    "\n",
    "    val_acc += acc(decoded_pred, label)\n",
    "print(\"val acc: \", val_acc/len(val_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a217d302-bc8e-4632-894b-71f2e04e3d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Given the article, what is the topic of the article? article: 12 Things That Will Be More Expensive In 2013  answer: healthy  answer: healthy  answer: healthy  answer: healthy  answer: healthy  answer: healthy People Are Not To Be A New Year's Resolution (VIDEO) answer: healthy (VIDEO)  answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy answer: healthy\",\n",
       " \"What is this article about? business/entertainment/food/healthy/parenting article: 'Star Wars' v. 'Lord Of The Rings': What's The Best Movie Franchise Of All Time? (VOTE) answer: entertainment answer: entertainment answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment for the World answer: entertainment in the World answer: entertainment for the World\",\n",
       " \"Given the article, what is the topic of the article? article: Troian Bellisario Says Mental Illness 'Almost Killed Me'  answer: entertainment  answer: entertainment  answer: entertainment  answer: entertainment Is The Best Thing You Should Know About The Internet (VIDEO) answer: entertainment answer: entertainment  answer: entertainment answer: healthy answer: entertainment and the World's Best Way to Be a Slave  answer: entertainment answer: entertainment answer: entertainment answer: entertainment answer: entertainment for the World answer: entertainment for the Holidays answer: entertainment for the Holidays answer: entertainment answer\",\n",
       " \"Given the article, what is the topic of the article? article: QUIZ: What Kind Of Beer Are You?  answer: food-Free  answer: food-Free-Driving Balance  answer: food-Free-Free-Driving Caramel  answer: food-Free-Backed-Bought, But Not To Be A New Year's Resolution answer: food-Free-Backed-Free-Driving Caramel Recipes (PHOTOS) answer: food-Free-Backed-Bought Recipes (PHO\"]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(pred, skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "90814739-0653-43a3-97cd-a4d22cdc0ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('llama_combined_0618')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d26a8-8d28-4ddd-8a45-fd4e57973fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e71fa-e0f9-46c9-a952-aa66f1abada5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19c6d1-79e2-4b24-84a1-b55e36d04075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
